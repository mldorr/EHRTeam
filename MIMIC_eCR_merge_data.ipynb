{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing the dataset for the big merge\n",
    "source: https://www.dataquest.io/blog/pandas-big-data/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#read in datasets\n",
    "df1 = pd.read_csv(\"C:/Users/Maggie/OneDrive/UW-BHI/2018Fall/CSE583/Project/mimic_merge4.csv\")\n",
    "df2 = pd.read_csv(\"C:/Users/Maggie/OneDrive/UW-BHI/2018Fall/CSE583/Project/mimic_prescriptions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimize numeric columns with subtypes\n",
    "def mem_usage(pandas_obj):\n",
    "    if isinstance(pandas_obj,pd.DataFrame):\n",
    "        usage_b = pandas_obj.memory_usage(deep=True).sum()\n",
    "    else: # we assume if not a df it's a series\n",
    "        usage_b = pandas_obj.memory_usage(deep=True)\n",
    "    usage_mb = usage_b / 1024 ** 2 # convert bytes to megabytes\n",
    "    return \"{:03.2f} MB\".format(usage_mb)\n",
    "\n",
    "df1_int = df1.select_dtypes(include=['int64'])\n",
    "df1_converted_int = df1_int.apply(pd.to_numeric,downcast='unsigned')\n",
    "\n",
    "print(mem_usage(df1_int))\n",
    "print(mem_usage(df1_converted_int))\n",
    "\n",
    "compare_ints = pd.concat([df1_int.dtypes,df1_converted_int.dtypes],axis=1)\n",
    "compare_ints.columns = ['before','after']\n",
    "compare_ints.apply(pd.Series.value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_int = df2.select_dtypes(include=['int64'])\n",
    "df2_converted_int = df2_int.apply(pd.to_numeric,downcast='unsigned')\n",
    "\n",
    "print(mem_usage(df2_int))\n",
    "print(mem_usage(df2_converted_int))\n",
    "\n",
    "compare_ints = pd.concat([df2_int.dtypes,df2_converted_int.dtypes],axis=1)\n",
    "compare_ints.columns = ['before','after']\n",
    "compare_ints.apply(pd.Series.value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#repeat with floats for df1\n",
    "df1_float = df1.select_dtypes(include=['float'])\n",
    "df1_converted_float = df1_float.apply(pd.to_numeric,downcast='float')\n",
    "\n",
    "print(mem_usage(df1_float))\n",
    "print(mem_usage(df1_converted_float))\n",
    "\n",
    "compare_floats = pd.concat([df1_float.dtypes,df1_converted_float.dtypes],axis=1)\n",
    "compare_floats.columns = ['before','after']\n",
    "compare_floats.apply(pd.Series.value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#repeat with floats for df2\n",
    "df2_float = df2.select_dtypes(include=['float'])\n",
    "df2_converted_float = df2_float.apply(pd.to_numeric,downcast='float')\n",
    "\n",
    "print(mem_usage(df2_float))\n",
    "print(mem_usage(df2_converted_float))\n",
    "\n",
    "compare_floats = pd.concat([df2_float.dtypes,df2_converted_float.dtypes],axis=1)\n",
    "compare_floats.columns = ['before','after']\n",
    "compare_floats.apply(pd.Series.value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create copy of original dataframes, assign optimized columns in place, and check improvements\n",
    "optimized_df1 = df1.copy()\n",
    "\n",
    "optimized_df1[df1_converted_int.columns] = df1_converted_int\n",
    "optimized_df1[df1_converted_float.columns] = df1_converted_float\n",
    "\n",
    "print(mem_usage(df1))\n",
    "print(mem_usage(optimized_df1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create copy of original dataframes, assign optimized columns in place, and check improvements\n",
    "optimized_df2 = df2.copy()\n",
    "\n",
    "optimized_df2[df2_converted_int.columns] = df2_converted_int\n",
    "optimized_df2[df2_converted_float.columns] = df2_converted_float\n",
    "\n",
    "print(mem_usage(df2))\n",
    "print(mem_usage(optimized_df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_obj = df1.select_dtypes(include=['object']).copy()\n",
    "df1_obj.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_obj = df2.select_dtypes(include=['object']).copy()\n",
    "df2_obj.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loop to iterate over each object column, \n",
    "#check if the number of unique values is less than 50%, \n",
    "#and if so, convert it to the category type.\n",
    "\n",
    "converted_obj_df1 = pd.DataFrame()\n",
    "\n",
    "for col in df1_obj.columns:\n",
    "    num_unique_values = len(df1_obj[col].unique())\n",
    "    num_total_values = len(df1_obj[col])\n",
    "    if num_unique_values / num_total_values < 0.5:\n",
    "        converted_obj_df1.loc[:,col] = df1_obj[col].astype('category')\n",
    "    else:\n",
    "        converted_obj_df1.loc[:,col] = df1_obj[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "converted_obj_df2 = pd.DataFrame()\n",
    "\n",
    "for col in df2_obj.columns:\n",
    "    num_unique_values = len(df2_obj[col].unique())\n",
    "    num_total_values = len(df2_obj[col])\n",
    "    if num_unique_values / num_total_values < 0.5:\n",
    "        converted_obj_df2.loc[:,col] = df2_obj[col].astype('category')\n",
    "    else:\n",
    "        converted_obj_df2.loc[:,col] = df2_obj[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mem_usage(df1_obj))\n",
    "print(mem_usage(converted_obj_df1))\n",
    "\n",
    "compare_obj_df1 = pd.concat([df1_obj.dtypes,converted_obj_df1.dtypes],axis=1)\n",
    "compare_obj_df1.columns = ['before','after']\n",
    "compare_obj_df1.apply(pd.Series.value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mem_usage(df2_obj))\n",
    "print(mem_usage(converted_obj_df2))\n",
    "\n",
    "compare_obj_df2 = pd.concat([df2_obj.dtypes,converted_obj_df2.dtypes],axis=1)\n",
    "compare_obj_df2.columns = ['before','after']\n",
    "compare_obj_df2.apply(pd.Series.value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_df1[converted_obj_df1.columns] = converted_obj_df1\n",
    "\n",
    "print(mem_usage(optimized_df1))\n",
    "print(mem_usage(df1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_df2[converted_obj_df2.columns] = converted_obj_df2\n",
    "\n",
    "print(mem_usage(optimized_df2))\n",
    "print(mem_usage(df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_df1.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_df2.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_merge5 = pd.merge(optimized_df1, optimized_df2, how='inner', left_on=['hadm_id', 'subject_id'], right_on=['hadm_id', 'subject_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Export\n",
    "#df_merge5.to_csv(\"C:/Users/Maggie/OneDrive/UW-BHI/2018Fall/CSE583/Project/mimic_merge5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_merge5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_usage(df_merge5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge5.dtypes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
